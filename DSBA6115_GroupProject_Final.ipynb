{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the workspace\n",
    "* Import required packages\n",
    "* create function definitions\n",
    "* import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import missingno as msno\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categories(df, new_column, dictionary, recoded_column, breaks, recoded_expression): \n",
    "    df[new_column] = np.nan\n",
    "    for key, value in dictionary.items():\n",
    "        matches = df.loc[df[recoded_column] == key]\n",
    "    #df_final['experienced'][matches.index] = value\n",
    "        if value >= breaks[0]: \n",
    "        #print(key, value)\n",
    "            df[new_column][matches.index] = recoded_expression[0]\n",
    "        elif value >= breaks[1] and value < breaks[0]: \n",
    "        #print(key, value)\n",
    "            df[new_column][matches.index] = recoded_expression[1]\n",
    "        elif value >= breaks[2] and value < breaks[1]:\n",
    "        #print(key, value)\n",
    "            df[new_column][matches.index] = recoded_expression[2]\n",
    "        elif value <breaks[2]: \n",
    "        #print(key, value)\n",
    "            df[new_column][matches.index] = recoded_expression[3]\n",
    "        else: \n",
    "            print('no match')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_counts(df, column):\n",
    "    dictionary = (df[column].value_counts(dropna=False).to_dict())\n",
    "    funder_quant = df[column].value_counts(dropna=False).quantile([.25, .5, .75])\n",
    "    return dictionary, funder_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(df): \n",
    "    obj_df = df.select_dtypes(include=[object])\n",
    "    obj_df[pd.isnull(obj_df)]  = 'NaN'\n",
    "    #obj_df.drop(['public_meeting', 'permit'], axis=1, inplace=True)\n",
    "    #(obj_df.to_csv('C:/Users/renee/Desktop/DSBA/Fall 2018/Group Project/Code/funder.csv'))\n",
    "    encoded_df = pd.DataFrame(obj_df.apply(LabelEncoder().fit_transform))\n",
    "    df.drop(obj_df.columns, axis=1, inplace=True)\n",
    "    new_df = df.join(encoded_df, how='left')\n",
    "    return(new_df)\n",
    "#print(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dummies(df):\n",
    "    new_df = df.get_dummies()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the training data sets\n",
    "\n",
    "training_x = pd.read_csv(\"C:/Users/renee/Desktop/DSBA/Fall 2018/Group Project/Data/TrainingData.csv\", index_col=\"id\", \n",
    "                         dtype = {'public_meeting': bool, 'permit': bool}) \n",
    "#dtype = {'funder': str} )\n",
    "training_y = pd.read_csv(\"C:/Users/renee/Desktop/DSBA/Fall 2018/Group Project/Data/TrainingLabels.csv\", index_col=\"id\")\n",
    "\n",
    "#import the test set\n",
    "test_set = pd.read_csv(\"C:/Users/renee/Desktop/DSBA/Fall 2018/Group Project/Data/TestData.csv\", \n",
    "                       dtype = { 'public_meeting': bool, 'permit': bool})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recorded_by has all same values. Drop because there is no information\n",
    "training_x.drop('recorded_by', inplace=True, axis=1)\n",
    "test_set.drop('recorded_by', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(training_x.head(5))\n",
    "#print(training_x.shape)\n",
    "#print(training_x.columns)\n",
    "#training_x.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(training_y.head(5))\\nprint(training_y.shape)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(training_y.head(5))\n",
    "print(training_y.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "* change datetype of date_recorded to correct format \n",
    "* replace 0s in the funder column to Unknown\n",
    "* impute missing values\n",
    "* recategorize funder and installer into new variables with 4 levels, based on their quartile ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the data without binning the large categorical variables \n",
    "def data_cleaning_full(training_df):\n",
    "    training_df.loc[:,['date_recorded']] = training_df[['date_recorded']].apply(pd.to_datetime, format='%m/%d/%Y')\n",
    "    training_df['date_recorded'] = training_df['date_recorded'].dt.strftime('%m%d%Y').astype(float)\n",
    "    training_df.fillna('Unknown')\n",
    "    #training_df[['public_meeting', 'permit']].fillna(\"\")\n",
    "    #training_df[['public_meeting', 'permit']].astype(bool)\n",
    "    #replace the 0's in the funder column with Unknown. Otherwise, the data type will not be consistent when \n",
    "    # trying to perform other operations on the values \n",
    "    training_df['funder'].loc[training_df['funder'] == '0'] = 'Unknown'\n",
    "    return training_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean data with binning large cateogrical variables \n",
    "def data_cleaning_bins(training_df): \n",
    "    df= data_cleaning_full(training_df)\n",
    "     # create dictionaries of the counts of the objects with a lot of classes\n",
    "    dict_funder, quants_funder = create_dict_counts(df, 'funder')\n",
    "    print(quants_funder)\n",
    "    dict_installer, quants_installer = create_dict_counts(df, 'installer')\n",
    "    new_df = map_categories(df, 'funder_experience', dict_funder, 'funder', (1356, 720, 455), \n",
    "                        ('very experienced', 'experienced', 'some experience', 'little experience' ))\n",
    "    new_df2 = map_categories(new_df, 'installer_experience', dict_installer, 'installer', (1269, 480, 390), \n",
    "                         ('very experienced', 'experienced', 'some experience', 'little experience'))\n",
    "    return new_df2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_recorded: 356\n",
      "funder: 1897\n",
      "installer: 2146\n",
      "wpt_name: 37400\n",
      "basin: 9\n",
      "subvillage: 19288\n",
      "region: 21\n",
      "lga: 125\n",
      "ward: 2092\n",
      "public_meeting: 3\n",
      "scheme_management: 13\n",
      "scheme_name: 2697\n",
      "permit: 3\n",
      "extraction_type: 18\n",
      "extraction_type_group: 13\n",
      "extraction_type_class: 7\n",
      "management: 12\n",
      "management_group: 5\n",
      "payment: 7\n",
      "payment_type: 7\n",
      "water_quality: 8\n",
      "quality_group: 6\n",
      "quantity: 5\n",
      "quantity_group: 5\n",
      "source: 10\n",
      "source_type: 7\n",
      "source_class: 3\n",
      "waterpoint_type: 7\n",
      "waterpoint_type_group: 6\n"
     ]
    }
   ],
   "source": [
    "# check the number of levels in the categorical variables\n",
    "\n",
    "obj_df = training_x.select_dtypes(include=[object])\n",
    "\n",
    "for obj in obj_df: \n",
    "    print(obj + \": \" + str(len(set(obj_df[obj]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = data_cleaning_full(training_x )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequencies(df, column):\n",
    "    for column_name in column: \n",
    "        col_name = str(column_name+'_counts') \n",
    "        #print(col_name)\n",
    "        counts = pd.DataFrame(df[column_name].value_counts())\n",
    "        #print(counts.index)\n",
    "        df = df.merge(counts, how='left', left_on=column_name, right_index=True)\n",
    "        #print(new_df)\n",
    "        #df = df.loc[df[col_name] == column_name] = counts\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = find_frequencies(df_cleaned, ('funder', 'installer', 'ward', 'scheme_name'))\n",
    "df_freq.to_csv(\"C:/Users/renee/Desktop/DSBA/Fall 2018/Group Project/Data/DataFreq.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_freq.columns)\n",
    "#print(df_freq.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['amount_tsh', 'date_recorded', 'funder_x', 'gps_height', 'installer_x',\n",
      "       'longitude', 'latitude', 'wpt_name', 'num_private', 'basin',\n",
      "       'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward_x',\n",
      "       'population', 'public_meeting', 'scheme_management', 'scheme_name_x',\n",
      "       'permit', 'construction_year', 'extraction_type',\n",
      "       'extraction_type_group', 'extraction_type_class', 'management',\n",
      "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
      "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
      "       'source_class', 'waterpoint_type', 'waterpoint_type_group', 'funder_y',\n",
      "       'installer_y', 'ward_y', 'scheme_name_y'],\n",
      "      dtype='object')\n",
      "(0, 42)\n",
      "Index(['amount_tsh', 'date_recorded', 'funder_x', 'gps_height', 'installer_x',\n",
      "       'longitude', 'latitude', 'wpt_name', 'num_private', 'basin',\n",
      "       'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward_x',\n",
      "       'population', 'public_meeting', 'scheme_management', 'scheme_name_x',\n",
      "       'permit', 'construction_year', 'extraction_type',\n",
      "       'extraction_type_group', 'extraction_type_class', 'management',\n",
      "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
      "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
      "       'source_class', 'waterpoint_type', 'waterpoint_type_group', 'funder_y',\n",
      "       'installer_y', 'ward_y', 'scheme_name_y'],\n",
      "      dtype='object')\n",
      "(0, 42)\n",
      "Index(['amount_tsh', 'date_recorded', 'funder_x', 'gps_height', 'installer_x',\n",
      "       'longitude', 'latitude', 'wpt_name', 'num_private', 'basin',\n",
      "       'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward_x',\n",
      "       'population', 'public_meeting', 'scheme_management', 'scheme_name_x',\n",
      "       'permit', 'construction_year', 'extraction_type',\n",
      "       'extraction_type_group', 'extraction_type_class', 'management',\n",
      "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
      "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
      "       'source_class', 'waterpoint_type', 'waterpoint_type_group', 'funder_y',\n",
      "       'installer_y', 'ward_y', 'scheme_name_y'],\n",
      "      dtype='object')\n",
      "(0, 42)\n",
      "Index(['amount_tsh', 'date_recorded', 'funder_x', 'gps_height', 'installer_x',\n",
      "       'longitude', 'latitude', 'wpt_name', 'num_private', 'basin',\n",
      "       'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward_x',\n",
      "       'population', 'public_meeting', 'scheme_management', 'scheme_name_x',\n",
      "       'permit', 'construction_year', 'extraction_type',\n",
      "       'extraction_type_group', 'extraction_type_class', 'management',\n",
      "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
      "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
      "       'source_class', 'waterpoint_type', 'waterpoint_type_group', 'funder_y',\n",
      "       'installer_y', 'ward_y', 'scheme_name_y'],\n",
      "      dtype='object')\n",
      "(0, 42)\n",
      "(0, 42)\n"
     ]
    }
   ],
   "source": [
    "list = ('funder_y', 'installer_y', 'ward_y', 'scheme_name_y')\n",
    "for column in list:\n",
    "    print(df_freq.columns)\n",
    "    df_freq = pd.DataFrame(df_freq.loc[df_freq[column]] != 1)\n",
    "    print(df_freq.shape)\n",
    "    #new_df = df_final.drop() for row in df_final if df_final[column].loc[df_final[column] == 1]\n",
    "    \n",
    "print(df_freq.shape)\n",
    "df_freq.to_csv(\"C:/Users/renee/Desktop/DSBA/Fall 2018/Group Project/Data/DataFreq.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Label Encoded to Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df, original): \n",
    "# dropping public_meeting. getting error \n",
    "#\"'<' not supported between instances of 'str' and 'bool'\", 'occurred at index public_meeting')\n",
    "#TO DO: research how to correct this. Data type is still mixed instead of bool which is causing error \n",
    "    temp_df = df.drop(['public_meeting', 'permit'], axis=1)\n",
    "    df_encoded = encode_df(temp_df)\n",
    "    df_encoded['public_meeting'] = original['public_meeting'].values\n",
    "    df_encoded['permit'] = original['permit'].values\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2554: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._where(-key, value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_encoded = label_encoding(df_freq, training_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: dropping the data_recorded for the imputation right now because otherwise column is throwing an error\n",
    "# TO DO: figure out why date format isn't working in imputation--> convert to UTC? \n",
    "\n",
    "#df_encoded.drop('date_recorded', inplace=True, axis=1) \n",
    "from sklearn.preprocessing import Imputer\n",
    "def impute_missing(df):\n",
    "    imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "    df_imputed = pd.DataFrame(imp.fit_transform(df), columns=df.columns)\n",
    "    return df_imputed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = impute_missing(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Random Forest to Predict Values coded as 0 that are \"unknown\" or missing\n",
    "* longitude \n",
    "* construction_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def impute_falsevalues(df, column): \n",
    "    test_y_long = df[[column]].loc[df[column] == 0]\n",
    "    test_x_long = df.loc[df[column] ==0]\n",
    "    training_x_long = df.loc[df[column] != 0]\n",
    "    training_y_long = df[column].loc[df[column] != 0]\n",
    "    training_x_long.drop(column, inplace=True, axis=1)\n",
    "    rf_regressor = RandomForestRegressor(n_estimators = 1000, max_depth = 10, \n",
    "                                     bootstrap=True, oob_score=True, random_state=1029, n_jobs=-2)\n",
    "    rf_regressor.fit(training_x_long, training_y_long)\n",
    "    #print(test_x_long.reshape(-1,1))\n",
    "    test_x_long.drop(column, inplace=True, axis=1)\n",
    "    #print(test_x_long)\n",
    "    long_pred = rf_regressor.predict(test_x_long)\n",
    "    df.loc[test_x_long.index, column] = long_pred\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "df_final = impute_falsevalues(df_imputed, 'longitude')\n",
    "df_final = impute_falsevalues(df_final, 'construction_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_final.columns)\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_final, training_y, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train AdaBoost Model (with Random Forest Base Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def run_AdaBoost(X_train, y_train, X_test, y_test):  \n",
    "    ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=30,\n",
    "                           min_impurity_decrease = .0000001, random_state=0),\n",
    "    n_estimators=5000,\n",
    "    learning_rate=.1,\n",
    "    algorithm=\"SAMME.R\", \n",
    "    )\n",
    "\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    preds = ada_clf.predict(X_test)\n",
    "    accuracy = (accuracy_score(preds, y_test))\n",
    "    confusion = confusion_matrix(preds, y_test)\n",
    "    model = ada_clf\n",
    "    return (accuracy, confusion, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.797053872053872\n",
      "[[5842  478 1151]\n",
      " [ 114  253   51]\n",
      " [ 485  132 3374]]\n"
     ]
    }
   ],
   "source": [
    "#y = np.ravel(training_y)\n",
    "accuracy, confusion, model = run_AdaBoost(X_train, y, X_test, y_test)\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(confusion)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def run_gradboost(X_train, y_train, X_test, y_test):\n",
    "    gb = GradientBoostingClassifier(n_estimators=5000, learning_rate=.1, max_depth=30, \n",
    "                                    random_state=1234, max_features=.75).fit(X_train, y_train)\n",
    "    preds = gb.predict(X_test)\n",
    "    accuracy = (accuracy_score(preds, y_test))\n",
    "    confusion = confusion_matrix(preds, y_test)\n",
    "    model = gb\n",
    "    return (accuracy, confusion, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9617508417508418\n",
      "[[31479   416   872]\n",
      " [  179  3766    69]\n",
      " [  601   135 21883]]\n"
     ]
    }
   ],
   "source": [
    "#y = np.ravel(training_y)\n",
    "accuracy_gb, confusion_gb, model_gb = run_gradboost(X_train, y, X_test, y_test)\n",
    "print(\"accuracy: \" + str(accuracy_gb))\n",
    "print(confusion_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_gb' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-995ca7424433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_gb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_gb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_gb' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(\"accuracy: \" + str(accuracy_gb))\n",
    "print(confusion_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomforest(X_train, y_train, X_test, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=5000, learning_rate=.1, max_depth=30, min_impurity_decrease = .000001 \n",
    "                                    random_state=1234, max_features=.75).fit(X_train, y_train)\n",
    "    preds = rf.predict(X_test)\n",
    "    accuracy = (accuracy_score(preds, y_test))\n",
    "    confusion = confusion_matrix(preds, y_test)\n",
    "    model = rf\n",
    "    return (accuracy, confusion, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rf, confusion_rf, model_rf = run_gradboost(X_train, y, df_final, training_y)\n",
    "print(\"accuracy: \" + str(accuracy_rf))\n",
    "print(confusion_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def run_svm(X_train, y_train, X_test, y_test):\n",
    "    svm = SVC(class_weight='balanced', n_jobs=-2).fit(X_train, y_train)\n",
    "    preds = svm.predict(X_test)\n",
    "    accuracy = (accuracy_score(preds, y_test))\n",
    "    confusion = confusion_matrix(preds, y_test)\n",
    "    model = svm\n",
    "    return (accuracy, confusion, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(training_y)\n",
    "accuracy, confusion, model_svm = run_svm(X_test, y_test, df_final, y)\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform 5-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X_test, y_test, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test set and create submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2554: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "df_test_cleaned = data_cleaning_full(test_set)\n",
    "df_test_freq = find_frequencies(df_test_cleaned, ('funder', 'installer', 'ward', 'scheme_name'))\n",
    "list = ('funder_y', 'installer_y', 'ward_y', 'scheme_name_y')\n",
    "#for column in list:\n",
    "   # df_test_freq = df_test_freq[column] != 1\n",
    "df_test_encoded = label_encoding(df_test_freq, test_set)\n",
    "df_test_imputed = impute_missing(df_test_encoded)\n",
    "df_test_final = impute_falsevalues(df_test_imputed, 'longitude')\n",
    "df_test_final = impute_falsevalues(df_test_final, 'construction_year')\n",
    "\n",
    "# drop some columns we know we won't use for model \n",
    "#df_final_test = df_imputed_test.drop(['funder', 'installer'], axis=1)\n",
    "#print(df_final_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_set[['id']]\n",
    "df_test_final.drop('id', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14850,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-6c49d7f52239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpreds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlist2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfinal_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msubmission_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#list1 = list(df_final_test.index)\n",
    "#index = np.reshape(list1, len(list1)).T\n",
    "preds_test = model.predict(df_test_final)\n",
    "print(preds_test.shape)\n",
    "list2 = list(preds_test)\n",
    "final_preds = np.reshape(list2, len(list2)).T\n",
    "submission_df = test_set[['id']]\n",
    "submission_df['status_group'] = final_preds\n",
    "             \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"C:/Users/renee/Desktop/DSBA/Fall 2018/Group Project/Data/Submission_AdaBoost.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14850,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "print(preds_test.shape)\n",
    "#list2 = list(preds_test)\n",
    "final_preds = np.reshape(preds_test, len(preds_test)).T\n",
    "submission_df = test_set[['id']]\n",
    "submission_df['status_group'] = final_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below is from other tests. Not used in current model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Encoding \n",
    "Instead of Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = encode_dummies(df_new2)\n",
    "accuracy2, confusion2 = run_AdaBoost(df_dummy)\n",
    "print(\"accuracy: \" + str(accuracy2))\n",
    "print(confusion2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Grid Search for Hyper-parameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'base_estimator__max_depth': 11, 'learning_rate': 0.1, 'n_estimators': 2501}\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tuned_parameters = [{'n_estimators': range(1,4001, 500), 'learning_rate': [.1, 1.6, .3],\n",
    "                     'base_estimator__max_depth': range(1,21,5), \n",
    "                    'base_estimator__max_features': ['auto', 'sqrt','log2']\n",
    "                    }]\n",
    "\n",
    "adaboost_tuned = GridSearchCV(AdaBoostClassifier(RandomForestClassifier(class_weight='balanced')), \n",
    "                              tuned_parameters, cv=5, \n",
    "                       error_score=0, n_jobs=-2)\n",
    "adaboost_tuned.fit(X_train, y)\n",
    "\n",
    "print(adaboost_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb.get_params().keys\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "tuned_parameters = [{'n_estimators': range(1,3000, 500), 'learning_rate': [.1, 1.5, .3],\n",
    "                     'max_depth': range(1,20,5), \n",
    "                   'max_features': ['auto', 'sqrt','log2']}]\n",
    "\n",
    "gb_tuned = GridSearchCV(GradientBoostingClassifier(), tuned_parameters, cv=10, \n",
    "                       error_score=0)\n",
    "gb_tuned.fit(X_train, y)\n",
    "-k\n",
    "print(gb_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(encoded_df['installer'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_preds = gb.predict(df_final_test)\n",
    "final_preds_gb = np.reshape(list2, len(list2)).T\n",
    "submission_df = test_set[['id']]\n",
    "submission_df['status_group'] = final_preds_gb\n",
    "submission_df.index = submission_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
